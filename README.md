# TartanVO Fine-Tuning Project

This project is based on the TartanVO model and focuses on fine-tuning it using several trajectories from the Euroc dataset. Follow the instructions below to successfully run the fine-tuning and evaluation processes.You need to first complete the TartanVO environment setup according to https://github.com/castacks/tartanvo , and delete the folders in TartanVO that are duplicated in my code, then replace them with my folders.Or you can also repo my code and set up the environment accroding to the file "readme_tartanvo.md".
Make sure the code on your computer has another three folders ,they are the "models"(the models of tartanvo and you trained are inside ),"data"(put your fine-tuning track inside),"results"(saving the output result of "FinalEvaluater.py" and "Evaluater_combine.py").
This project can effectively reduce the error of any trajectory after fine-tuning. If you have any questions, I'm more than happy to answer them in the Issues section.

## Data Preparation

### Step 1: Preprocess the Data

1. Run the data processing scripts `photoprocessing` and `photoprocessingforEuroc`.
2. If your dataset type is not Euroc, modify the data processing scripts accordingly.
3. Ensure that the final data format is `(batch_size, 8)`, where:
   - The first column is the timestamp.
   - Columns 2 to 4 are spatial positions.
   - Columns 5 to 8 are rotation quaternions in `wxyz` format. (Using `xyzw` format will cause bugs.)

### Step 2: Store the Data

1. Save the processed images in `data/targetImageFolder`.
2. Save the selected ground truth data in a dedicated folder within the `data` directory for your fine-tuning data. Ensure you remember the locations of these data files.

**Note:**

- The models are automatically saved when running `photoprocessing` or `photoprocessingforEuroc`. Remember to modify these files according to your needs.

## Fine-Tuning Process

### Step 1: Modify Script Paths

1. In `fine_tuning_script.py`, update the paths for the images and ground truth data to your saved locations. The default image path is `data/targetImageFolder`.

### Step 2: Adjust Training Parameters

1. Adjust the `subset` part of the code to split the training and validation sets.
2. Set the number of epochs, `batch_size`, `worker_num`, and the model save location based on your GPU performance. It is recommended to create a new folder under `models` for each training session to save the model.
3. To effectively reduce errors, train for at least 100 epochs.

### Step 3: Start Training

1. Run the `fine_tuning_script.py` script. During training, the training and validation errors will be saved in a CSV file within the same folder as all models. If the training is interrupted before completing all epochs, this CSV file will not be created.

## Model Evaluation

### Step 1: Select the Model

1. After training, choose the best model based on the validation error (`val_loss`).

### Step 2: Run Final Evaluation

1. Use the `Final_Evaluater.py` script to evaluate the model. This script will:
   - Generate pose parameters based on the model's predictions and save them in a specified CSV file.
   - Save a TXT version of this file in the `results` folder.
   - Create a comparison plot of the aligned predicted trajectory and the ground truth trajectory in the `results` folder.
   - Print the ATE value in the terminal and display it in the PNG image. If not recorded, this value can also be found in the `results` folder.

2. Execution Command:
   Run `FinalEvaluater.py` in the terminal with the required parameters:
   python FinalEvaluater.py --batch-size 16 --worker-num 4 --model-name yourmodelname --euroc (if it's Euroc) --test-dir the folder you load your evaluate images --pose-file the position of your evaluate groundtruth --savePose the position to save that csv file of your prediction

## Note:

Before running the evaluator, if you want to generate a prediction result display image and TXT file in the `results` folder, move your model directly to the `models` folder. If the `results` folder becomes too cluttered, you can run your model in a subfolder under `models` that you created to store multiple fine-tuned models. This may cause a small bug where the `results` folder won't generate files, but you can still read the ATE value.

## Enhanced Fine-Tuning (Optional)

### Step 1: Modify the Script for Enhanced Fine-Tuning

If you want to use the original TartanVO model and the fine-tuned model together to generate a combined result, modify the `fine_tuning_script.py` code:

   - Remove the comment symbols for the parameters related to rotation freezing.

### Step 2: Run the Combined Evaluation

After generating the fine-tuned result, run `Evaluater_combine.py` with the required parameters specified in the script.

## Visualization

### Step 1: Run the Drawing Script

Additionally, a drawing script `drawpicture.py` is provided. This script requires the pose and rotation prediction data generated by the evaluator (`--savePose` specified CSV file) and the preprocessed ground truth file (ensure the header is removed from the ground truth file to avoid bugs).

   - The drawing script focuses only on spatial positions and ignores rotations.
   - Modify the input parameter addresses in `drawpicture.py` and run the script to read and visualize the results.

By following these steps, you can fine-tune the TartanVO model effectively, evaluate its performance accurately, and visualize the results.
